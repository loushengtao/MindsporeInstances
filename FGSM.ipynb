{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FGSW网络对抗攻击\n",
    "<hr>\n",
    "\n",
    "FGSW(Fast Gradient sign Methods)梯度符号攻击是对抗性攻击领域，尤其是白盒攻击领域的鼻祖之作，现在我们用Mindspore来实现FGSM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对抗样本定义\n",
    "\n",
    "Szegedy在2013年最早提出对抗样本的概念:\n",
    "\n",
    "$$\\hat{x}=x+\\epsilon sign(\\nabla_{x}J(\\theta,x,y))$$\n",
    "\n",
    "<img src=\"img\\FGSM1.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### 训练模型\n",
    "\n",
    "本案例将使用MNIST训练一个进度达标的LeNet网络，然后运行上文中所提到的FGSM攻击方法，达到欺骗网络模型，让模型实现错误分类的效果，由于在另一篇文章里已经详细介绍了LeNet网络的训练，这里就快速过一遍"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(9828:16456,MainProcess):2022-08-06-01:37:41.684.242 [mindspore\\dataset\\engine\\datasets_user_defined.py:656] Python multiprocessing is not supported on Windows platform.\n",
      "[WARNING] ME(9828:16456,MainProcess):2022-08-06-01:37:42.708.10 [mindspore\\dataset\\engine\\datasets_user_defined.py:656] Python multiprocessing is not supported on Windows platform.\n",
      "[WARNING] ME(9828:16456,MainProcess):2022-08-06-01:37:42.713.10 [mindspore\\dataset\\core\\validator_helpers.py:799] 'Resize' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'Resize' from mindspore.dataset.vision instead.\n",
      "[WARNING] ME(9828:16456,MainProcess):2022-08-06-01:37:42.718.10 [mindspore\\dataset\\core\\validator_helpers.py:799] 'Rescale' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'Rescale' from mindspore.dataset.vision instead.\n",
      "[WARNING] ME(9828:16456,MainProcess):2022-08-06-01:37:42.723.10 [mindspore\\dataset\\core\\validator_helpers.py:799] 'Rescale' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'Rescale' from mindspore.dataset.vision instead.\n",
      "[WARNING] ME(9828:16456,MainProcess):2022-08-06-01:37:42.723.10 [mindspore\\dataset\\core\\validator_helpers.py:799] 'HWC2CHW' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'HWC2CHW' from mindspore.dataset.vision instead.\n",
      "[WARNING] ME(9828:16456,MainProcess):2022-08-06-01:37:42.728.10 [mindspore\\dataset\\core\\validator_helpers.py:799] 'Resize' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'Resize' from mindspore.dataset.vision instead.\n",
      "[WARNING] ME(9828:16456,MainProcess):2022-08-06-01:37:42.733.10 [mindspore\\dataset\\core\\validator_helpers.py:799] 'Rescale' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'Rescale' from mindspore.dataset.vision instead.\n",
      "[WARNING] ME(9828:16456,MainProcess):2022-08-06-01:37:42.738.10 [mindspore\\dataset\\core\\validator_helpers.py:799] 'Rescale' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'Rescale' from mindspore.dataset.vision instead.\n",
      "[WARNING] ME(9828:16456,MainProcess):2022-08-06-01:37:42.743.11 [mindspore\\dataset\\core\\validator_helpers.py:799] 'HWC2CHW' from mindspore.dataset.vision.c_transforms is deprecated from version 1.8 and will be removed in a future version. Use 'HWC2CHW' from mindspore.dataset.vision instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:[  0/  5], step:[ 1875/ 1875], loss:[2.286/2.302], time:3.001 ms, lr:0.01000\n",
      "Epoch time: 8666.509 ms, per step time: 4.622 ms, avg loss: 2.302\n",
      "Epoch:[  1/  5], step:[ 1875/ 1875], loss:[1.439/2.263], time:4.501 ms, lr:0.01000\n",
      "Epoch time: 10671.359 ms, per step time: 5.691 ms, avg loss: 2.263\n",
      "Epoch:[  2/  5], step:[ 1875/ 1875], loss:[0.004/0.166], time:30.005 ms, lr:0.01000\n",
      "Epoch time: 10832.887 ms, per step time: 5.778 ms, avg loss: 0.166\n",
      "Epoch:[  3/  5], step:[ 1875/ 1875], loss:[0.012/0.063], time:3.000 ms, lr:0.01000\n",
      "Epoch time: 11442.493 ms, per step time: 6.103 ms, avg loss: 0.063\n",
      "Epoch:[  4/  5], step:[ 1875/ 1875], loss:[0.112/0.049], time:2.501 ms, lr:0.01000\n",
      "Epoch time: 11266.963 ms, per step time: 6.009 ms, avg loss: 0.049\n"
     ]
    }
   ],
   "source": [
    "from mindvision.dataset import Mnist\n",
    "import mindspore as ms\n",
    "import mindspore.nn as nn\n",
    "from mindvision.engine.callback import LossMonitor\n",
    "from sklearn import config_context\n",
    "\n",
    "class LeNet5(nn.Cell):\n",
    "    def __init__(self,num_class=10,num_channel=1):\n",
    "        super(LeNet5,self).__init__()\n",
    "        # 卷积层1，通道：1-6 卷积核大小：5*5 \n",
    "        self.conv1=nn.Conv2d(num_channel,6,5,pad_mode='valid')\n",
    "        # 卷积层2，通道：6-16 卷积核大小：5*5 \n",
    "        self.conv2=nn.Conv2d(6,16,5,pad_mode='valid')\n",
    "        # 三个全连接层Dense\n",
    "        self.fc1=nn.Dense(16*5*5,120)\n",
    "        self.fc2=nn.Dense(120,84)\n",
    "        self.fc3=nn.Dense(84,num_class)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.max_pool2d=nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "        self.flatten=nn.Flatten()\n",
    "    \n",
    "    def construct(self,x):\n",
    "        # 构建前向网络\n",
    "        x=self.conv1(x) # C:1-6 N:32-5+1=28\n",
    "        x=self.relu(x)\n",
    "        x=self.max_pool2d(x) # C:6-6 N:28/2=14\n",
    "        x=self.conv2(x) # C:6-16 N: 14-5+1=10\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool2d(x) # C:16-16 n:10/2=5\n",
    "        x = self.flatten(x) # 16,5,5->16*5*5\n",
    "        x = self.fc1(x) # 16*5*5->120\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x) # 120->84\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x) # 84->10\n",
    "        return x\n",
    "# 创建网络对象\n",
    "network=LeNet5(num_class=10)\n",
    "\n",
    "# 加载数据集\n",
    "download_train=Mnist(path=\"./mnist\",split=\"train\",shuffle=True,download=True)\n",
    "download_eval=Mnist(path=\"./mnist\",split=\"test\",download=True)\n",
    "dataset_train=download_train.run()\n",
    "dataset_eval=download_eval.run()\n",
    "\n",
    "# 定义优化器和损失函数\n",
    "net_loss=nn.SoftmaxCrossEntropyWithLogits(sparse=True,reduction='mean')\n",
    "net_opt=nn.Momentum(network.trainable_params(),learning_rate=0.01,momentum=0.9)\n",
    "\n",
    "# 若想查询每一个epoch完毕之后的参数，则启用下面两句来下载check_point\n",
    "# config_ck=ms.CheckpointConfig(save_checkpoint_steps=1875,keep_checkpoint_max=10)\n",
    "# ckpoint=ms.ModelCheckpoint(prefix=\"checkpoint_lent\",config=config_ck)\n",
    "\n",
    "model=ms.Model(network,loss_fn=net_loss,optimizer=net_opt,metrics={'accuracy'})\n",
    "model.train(5,dataset_train,callbacks=[LossMonitor(0.01,1875)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 网络训练完毕，让我们看看训练完网络的准确性\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.9730568910256411}\n"
     ]
    }
   ],
   "source": [
    "acc=model.eval(dataset_eval)\n",
    "print(\"{}\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### FGSM攻击\n",
    "\n",
    "在得到精准的LeNet网络之后，下面将会采用FGSM攻击方法，在图像中加载噪声之后重新测试，先通过损失函数求反向梯度：\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mindspore.ops as ops\n",
    "\n",
    "class WithLossCell(nn.Cell):\n",
    "    # 包装网络损失函数\n",
    "    def __init__(self, network,loss_fn):\n",
    "        super(WithLossCell,self).__init__()\n",
    "        self._network=network\n",
    "        self._loss_fn=loss_fn\n",
    "\n",
    "    def construct(self,data,label):\n",
    "        out=self._network(data)\n",
    "        return self._loss_fn(out,label)\n",
    "\n",
    "class GradWrapWithLoss(nn.Cell):\n",
    "    def __init__(self,network):\n",
    "        super(GradWrapWithLoss,self).__init__()\n",
    "        self._grad_all=ops.composite.GradOperation(get_all=True,sens_param=False)\n",
    "        self._network=network\n",
    "    \n",
    "    def construct(self,inputs,labels):\n",
    "        gout=self._grad_all(self._network)(inputs,labels)\n",
    "        return gout[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 构造完损失函数和求梯度类之后即可利用上面的公式进行攻击\n",
    "\n",
    "$$\\hat{x}=x+\\epsilon sign(\\nabla_{x}J(\\theta,x,y))$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class FastGradientSignMethod:\n",
    "    def __init__(self,network,eps=0.07,loss_fn=None):\n",
    "        self._network=network\n",
    "        self._eps=eps\n",
    "        with_loss_cell=WithLossCell(self._network,loss_fn)\n",
    "        self._grad_all=GradWrapWithLoss(with_loss_cell)\n",
    "        self._grad_all.set_train()\n",
    "    \n",
    "    def _gradient(self,inputs,labels):\n",
    "        # 求出梯度\n",
    "        out_grad=self._grad_all(inputs,labels)\n",
    "        gradient=out_grad.asnumpy()\n",
    "        gradient=np.sign(gradient)\n",
    "        return gradient\n",
    "    \n",
    "    def generate(self,inputs,labels):\n",
    "        # 实现FGSM\n",
    "        inputs_tensor=ms.Tensor(inputs)\n",
    "        labels_tensor=ms.Tensor(labels)\n",
    "        gradient=self._gradient(inputs_tensor,labels_tensor)\n",
    "        # 产生扰动\n",
    "        perturbation=self._eps*gradient\n",
    "        adv_x=inputs+perturbation\n",
    "        return adv_x\n",
    "\n",
    "    def batch_generate(self,inputs,labels,batch_size=32):\n",
    "        # 对数据集进行处理\n",
    "        arr_x=inputs\n",
    "        arr_y=labels\n",
    "        len_x=len(inputs)\n",
    "        batches=int(len_x/batch_size) # 计算batch数\n",
    "        res=[]\n",
    "        for i in range(batches):\n",
    "            x_batch=arr_x[i*batch_size:(i+1)*batch_size]\n",
    "            y_batch=arr_y[i*batch_size:(i+1)*batch_size]\n",
    "            adv_x=self.generate(x_batch,y_batch)\n",
    "            res.append(adv_x)\n",
    "        adv_x=np.concatenate(res,axis=0)\n",
    "        return adv_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "再次处理MINIST数据集中测试集的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 9 ... 9 0 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "images=[]\n",
    "labels=[]\n",
    "test_images=[]\n",
    "test_labels=[]\n",
    "predict_labels=[]\n",
    "\n",
    "ds_test=dataset_eval.create_dict_iterator(output_numpy=True)\n",
    "\n",
    "\n",
    "\n",
    "for data in ds_test:\n",
    "    images=data['image'].astype(np.float32)\n",
    "    labels=data['label']\n",
    "    test_images.append(images)\n",
    "    test_labels.append(labels)\n",
    "    pred_labels=np.argmax(model.predict(ms.Tensor(images)).asnumpy(),axis=1)\n",
    "    predict_labels.append(pred_labels)\n",
    "\n",
    "test_images = np.concatenate(test_images)\n",
    "predict_labels = np.concatenate(predict_labels)\n",
    "true_labels = np.concatenate(test_labels) # concatenate拉成一个维度\n",
    "print(true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 运行攻击\n",
    "\n",
    "由FGSM攻击公式中可以看出，攻击参数$\\epsilon$越大，对梯度的改变就越大。当$\\epsilon$为零时则攻击效果不体现。$$\\eta=\\epsilon sign(\\nabla_{x}J(\\theta))$$\n",
    "\n",
    "> $\\epsilon$为0时"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9885817307692307\n"
     ]
    }
   ],
   "source": [
    "import mindspore.ops as ops\n",
    "\n",
    "fgsm = FastGradientSignMethod(network, eps=0.0, loss_fn=net_loss)\n",
    "advs = fgsm.batch_generate(test_images, true_labels, batch_size=32)\n",
    "\n",
    "adv_predicts = model.predict(ms.Tensor(advs)).asnumpy()\n",
    "adv_predicts = np.argmax(adv_predicts, axis=1)\n",
    "accuracy = np.mean(np.equal(adv_predicts, true_labels))\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> $\\epsilon$为0.9时"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29837740384615385\n"
     ]
    }
   ],
   "source": [
    "fgsm = FastGradientSignMethod(network, eps=0.5, loss_fn=net_loss)\n",
    "advs = fgsm.batch_generate(test_images, true_labels, batch_size=32)\n",
    "\n",
    "adv_predicts = model.predict(ms.Tensor(advs)).asnumpy()\n",
    "adv_predicts = np.argmax(adv_predicts, axis=1)\n",
    "accuracy = np.mean(np.equal(adv_predicts, true_labels))\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，acc变的很低，现在我们来看看受攻击图片的实际形态："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18600\\1985354247.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0madv_examples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madvs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mori_examples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "adv_examples = np.transpose(advs[:10], [0, 2, 3, 1])\n",
    "ori_examples = np.transpose(test_images[:10], [0, 2, 3, 1])\n",
    "\n",
    "plt.figure(figsize=(10, 3), dpi=120)\n",
    "for i in range(10):\n",
    "    plt.subplot(3, 10, i+1)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(np.squeeze(ori_examples[i]))\n",
    "    plt.subplot(3, 10, i+11)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(np.squeeze(adv_examples[i]))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实际上图片发生的变化不大，人眼还是可以非常清晰明了的识别的，但是在精度测试中缺严重下降，这揭示了神经网络的脆弱性"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f21bb2d5c565dbc33d815445cee0d4e3f2f7951520fd8c0e3b4200672f41bfe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
